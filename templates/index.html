<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="description" content="A comprehensive guide for Ruby gem installation and Google Generative AI integration. Learn about package structure, dependencies, and how to implement AI search functionality with clean code examples.">
    <meta name="copyright" content="© 2025 Niladri Das. All rights reserved.">
    <meta name="author" content="Niladri Das">
    <meta name="publish_date" content="2025-04-22">
    <meta name="date" content="2025-04-22">

    <!-- Open Graph / Social Media Meta Tags -->
    <meta property="og:title" content="Gem Installation & Google Generative AI">
    <meta property="og:description" content="A clean, minimal interface for Ruby gem installation and Google's Generative AI. Explore algorithm solutions, API integration examples, and learn how to implement AI search functionality with the latest Gemini models.">
    <meta property="og:image" content="https://raw.githubusercontent.com/bniladridas/gemini-ai-search/main/static/img/png/og-image.png">
    <meta property="og:url" content="{{ request.url_root }}">
    <meta property="og:type" content="website">
    <meta property="og:author" content="Niladri Das">
    <meta property="article:published_time" content="2025-04-22">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@bniladridas">

    <title>Gem Installation & Google Generative AI</title>
    <link rel="icon" href="{{ url_for('static', filename='img/favicon.svg') }}" type="image/svg+xml">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/marked/marked.min.css">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        :root {
            --text: #2c2c2c;
            --muted: #6b6b6b;
            --background: #fff;
            --spacing: clamp(1.5rem, 5vw, 2.5rem);
            --google-blue: #4285F4;
            --google-red: #EA4335;
            --google-text: #202124;
        }

        * {
            box-sizing: border-box;
            margin: 0;
        }

        html {
            -webkit-text-size-adjust: 100%;
        }

        body {
            font-family: -apple-system, system-ui, sans-serif;
            font-size: 15px;
            line-height: 1.5;
            max-width: 42rem;
            width: 100%;
            margin: var(--spacing) auto;
            padding: 0 var(--spacing);
            color: var(--text);
            background: var(--background);
            text-rendering: optimizeLegibility;
            -webkit-font-smoothing: antialiased;
            box-sizing: border-box;
        }

        h1 {
            font-size: 1.1rem;
            font-weight: 500;
            letter-spacing: -0.01em;
            margin-bottom: calc(var(--spacing) * 1.2);
        }

        h2 {
            font-size: 0.85rem;
            font-weight: 500;
            margin-top: calc(var(--spacing) * 0.8);
            color: var(--muted);
        }

        p {
            font-size: 0.85rem;
            color: var(--muted);
        }

        code {
            font-family: ui-monospace, monospace;
            font-size: 0.85rem;
            line-height: 1.4;
            display: block;
            margin: 0.4rem 0 calc(var(--spacing) * 0.7);
            color: var(--text);
        }

        body > p:last-child {
            margin-top: var(--spacing);
            font-size: 0.8rem;
            color: var(--muted);
            opacity: 0.8;
        }

        h1 {
            margin-top: calc(var(--spacing) * 1.5);
            padding-top: calc(var(--spacing) * 0.8);
            border-top: 1px solid rgba(0,0,0,0.07);
        }

        h1:first-of-type {
            margin-top: 0;
            padding-top: 0;
            border-top: none;
        }

        h2 {
            color: var(--google-red);
            margin-bottom: 0.2rem;
        }

        .simple-search {
            margin-top: 0.5rem;
            margin-bottom: 1.5rem;
        }

        .prompt-input {
            width: 100%;
            padding: 0.6rem;
            font-family: inherit;
            font-size: 0.85rem;
            border: 1px solid rgba(0,0,0,0.1);
            border-radius: 4px;
            background: rgba(0,0,0,0.02);
            margin-bottom: 0.5rem;
        }

        .prompt-input:focus {
            outline: none;
            border-color: var(--google-blue);
            background: white;
        }

        .prompt-button {
            padding: 0.5rem 1rem;
            font-family: inherit;
            font-size: 0.8rem;
            background: var(--google-blue);
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            opacity: 0.9;
            display: block;
            margin-bottom: 1rem;
        }

        .prompt-button:hover {
            opacity: 1;
        }

        .response-container {
            padding: 1rem;
            background: rgba(0,0,0,0.02);
            border-radius: 4px;
            font-size: 0.85rem;
            line-height: 1.5;
            min-height: 3rem;
            font-family: ui-monospace, monospace;
        }

        .tts-button {
            padding: 0.5rem 1rem;
            font-family: inherit;
            font-size: 0.8rem;
            background: var(--google-red);
            color: white;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            opacity: 0.9;
            display: none;
            margin-top: 0.5rem;
        }

        .tts-button:hover {
            opacity: 1;
        }

        .audio-player {
            width: 100%;
            margin-top: 0.5rem;
            display: none;
        }





        /* Mobile-specific styles */
        @media (max-width: 600px) {
            :root {
                --spacing: 1rem;
            }

            body {
                font-size: 14px;
                padding: 0 0.8rem;
            }

            code {
                font-size: 0.7rem;
                line-height: 1.3;
            }

            .prompt-input {
                font-size: 0.8rem;
            }

            h1 {
                font-size: 1rem;
            }

            h2 {
                font-size: 0.8rem;
            }

            p {
                font-size: 0.8rem;
            }
        }


    </style>
</head>
<body>
    <div class="logo-container">
        <img src="{{ url_for('static', filename='img/logo.svg') }}" alt="ND Logo" class="logo">
    </div>
    <h1>Gem Installation</h1>

    <h2>Start</h2>
    <p>Initial command</p>
    <code>sudo gem install friday_gemini_ai</code>

    <h2>Challenge</h2>
    <p>Version mismatch</p>
    <code>ruby -v</code>

    <h2>Solution</h2>
    <p>Version update</p>
    <code>rbenv global 3.2.2</code>

    <h2>Result</h2>
    <p>Success</p>
    <code>Successfully installed httparty-0.21.0
4 gems installed</code>

    <p>Always verify Ruby version before installing gems.</p>

    <h1>Google Generative AI</h1>

    <h2>Package Info</h2>
    <p>Details</p>
    <code>Name: google-generativeai
Version: 0.3.1
Summary: Google Generative AI High level API client library and tools.
Home-page: https://github.com/google/generative-ai-python
Author: Google LLC
Author-email: googleapis-packages@google.com
License: Apache 2.0
Location: /Users/niladridas/Desktop/te/.venv/lib/python3.13/site-packages
Requires: google-ai-generativelanguage, google-api-core, google-auth, protobuf, tqdm
Required-by:</code>

    <h2>Package Structure</h2>
    <p>Key components</p>
    <code>google/generativeai - Main package directory
google_generativeai-0.3.1-py3.11-nspkg.pth
google_generativeai-0.3.1.dist-info/ - Package metadata</code>

    <h2>Dependencies</h2>
    <p>Installed packages</p>
    <code>google_ai_generativelanguage-0.4.0.dist-info
google_api_core-2.24.2.dist-info
google_auth-2.39.0.dist-info
googleapis_common_protos-1.70.0.dist-info</code>

    <h1>Algorithm Problems</h1>

    <h2>Error: Network response was not ok</h2>
    <p>Problem: The Gemini API integration was failing with "Network response was not ok" error due to incorrect API usage.</p>
    <code># INCORRECT APPROACH (causing the error)
# This code was trying to use a Client class that doesn't exist in the installed version

client = genai.Client(
    api_key=os.environ.get("GEMINI_API_KEY"),
)

response = client.models.generate_content(
    model=model,
    contents=contents,
    config=generate_content_config,
)

# CORRECT APPROACH (solution)
# Configure the API globally and use GenerativeModel directly

# Set up the API key globally
genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))

# Create a GenerativeModel instance
model = genai.GenerativeModel('gemini-1.5-flash')

# Generate the response with a simpler interface
response = model.generate_content(prompt)</code>

    <h2>Two Sum</h2>
    <p>Problem: Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.</p>
    <code># Time Complexity: O(n)
# Space Complexity: O(n)

def twoSum(nums, target):
    # Create a hash map to store values and their indices
    hash_map = {}

    # Iterate through the array
    for i, num in enumerate(nums):
        # Calculate the complement
        complement = target - num

        # If complement exists in hash map, return its index and current index
        if complement in hash_map:
            return [hash_map[complement], i]

        # Otherwise, add current number and its index to hash map
        hash_map[num] = i

    # If no solution is found
    return []</code>

    <h2>Maximum Subarray</h2>
    <p>Problem: Given an integer array nums, find the contiguous subarray with the largest sum and return its sum.</p>
    <code># Time Complexity: O(n)
# Space Complexity: O(1)

def maxSubArray(nums):
    # Initialize variables
    current_sum = max_sum = nums[0]

    # Iterate through the array starting from the second element
    for num in nums[1:]:
        # Either start a new subarray or continue the previous one
        current_sum = max(num, current_sum + num)

        # Update max_sum if current_sum is greater
        max_sum = max(max_sum, current_sum)

    return max_sum</code>

    <h1>Niladri Das</h1>
    <h2>Software Engineer</h2>
    <p>Skills</p>
    <code>C++, Python, JavaScript, Flask, React, Machine Learning, API Integration</code>

    <h2>Experience</h2>
    <p>Background</p>
    <code>Specialized in building AI-powered applications and integrating with generative AI models</code>

    <h2>Projects</h2>
    <p>Recent work</p>
    <code>Gemini API Integration, Algorithm Problem Solver, Responsive Web Applications</code>

    <h2>Contact</h2>
    <p>Professional</p>
    <code>LinkedIn: https://www.linkedin.com/in/bniladridas/</code>

    <h1>AI Search</h1>
    <h2>Ask a Question</h2>
    <p>Enter your prompt and optionally listen to the response</p>
    <div class="simple-search">
        <textarea class="prompt-input" placeholder="Enter your question or prompt here..." rows="3"></textarea>
        <button class="prompt-button">Submit</button>
        <div class="response-container" id="response"></div>
        <button class="tts-button" id="tts-button">Listen (Text to Speech)</button>
        <audio class="audio-player" id="audio-player" controls></audio>
    </div>

    <h2>Implementation</h2>
    <p>Python code</p>
    <code># To run this code you need to install the following dependencies:
# pip install google-generativeai

import os
import google.generativeai as genai

# Configure the API
genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))

# Create a model instance with the newer model
model = genai.GenerativeModel('gemini-2.5-flash-preview-04-17')

# Generate content
response = model.generate_content("Your prompt here")

# Print the response
print(response.text)</code>

    <h2>Text-to-Speech Synthesis</h2>
    <p>Convert AI responses to natural-sounding speech</p>
    <code># Text-to-Speech implementation using Google's gTTS library
# pip install gtts

from gtts import gTTS
import os
import uuid
import tempfile

# Create a directory for temporary audio files
TEMP_AUDIO_DIR = os.path.join(tempfile.gettempdir(), 'gemini_tts')
os.makedirs(TEMP_AUDIO_DIR, exist_ok=True)

# Convert text to speech
def text_to_speech(text):
    # Generate a unique filename
    filename = f"{uuid.uuid4()}.mp3"
    filepath = os.path.join(TEMP_AUDIO_DIR, filename)

    # Convert text to speech using Google's TTS engine
    tts = gTTS(text=text, lang='en', slow=False)
    tts.save(filepath)

    # Return the file path to be served to the client
    return filepath</code>

    <h2>Copyright Notice</h2>
    <p>Legal information</p>
    <code>© 2025 Niladri Das. All rights reserved. Using this template or any part of this design is strictly prohibited without direct permission from the author.</code>

    <script>
        // Initialize marked.js for markdown rendering
        marked.setOptions({
            breaks: true,
            gfm: true
        });

        // Function to handle prompt submission
        function submitPrompt() {
            const promptInput = document.querySelector('.prompt-input').value;
            const responseContainer = document.getElementById('response');
            const ttsButton = document.getElementById('tts-button');
            const audioPlayer = document.getElementById('audio-player');

            // Hide TTS button and audio player when submitting a new prompt
            ttsButton.style.display = 'none';
            audioPlayer.style.display = 'none';
            audioPlayer.pause();
            audioPlayer.src = '';

            if (!promptInput.trim()) {
                responseContainer.innerHTML = '<em>Please enter a prompt</em>';
                return;
            }

            // Show loading state
            responseContainer.innerHTML = '<em>Thinking...</em>';

            // Make an actual API call to the Flask backend
            fetch('/api/generate', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ prompt: promptInput })
            })
            .then(response => {
                if (!response.ok) {
                    throw new Error('Network response was not ok');
                }
                return response.json();
            })
            .then(data => {
                // Render the response as markdown
                responseContainer.innerHTML = marked.parse(data.response);

                // Show the TTS button if we have a response
                if (data.response && data.response.trim()) {
                    ttsButton.style.display = 'block';
                    // Store the response text as a data attribute on the button
                    ttsButton.setAttribute('data-text', data.response);
                }
            })
            .catch(error => {
                console.error('Error:', error);
                responseContainer.innerHTML = `<em>Error: ${error.message}</em>`;
            });
        }

        // Function to handle text-to-speech
        function textToSpeech() {
            const ttsButton = document.getElementById('tts-button');
            const audioPlayer = document.getElementById('audio-player');
            const text = ttsButton.getAttribute('data-text');

            if (!text) {
                return;
            }

            // Disable the button while processing
            ttsButton.disabled = true;
            ttsButton.textContent = 'Processing...';

            // Make an API call to the text-to-speech endpoint
            fetch('/api/text-to-speech', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ text: text })
            })
            .then(response => {
                if (!response.ok) {
                    throw new Error('Network response was not ok');
                }
                return response.blob();
            })
            .then(blob => {
                // Create a URL for the audio blob
                const audioUrl = URL.createObjectURL(blob);

                // Set the audio source and display the player
                audioPlayer.src = audioUrl;
                audioPlayer.style.display = 'block';

                // Play the audio
                audioPlayer.play();

                // Re-enable the button
                ttsButton.disabled = false;
                ttsButton.textContent = 'Listen (Text to Speech)';
            })
            .catch(error => {
                console.error('Error:', error);
                alert(`Error generating speech: ${error.message}`);

                // Re-enable the button
                ttsButton.disabled = false;
                ttsButton.textContent = 'Listen (Text to Speech)';
            });
        }

        // Handle button clicks
        document.querySelector('.prompt-button').addEventListener('click', submitPrompt);
        document.getElementById('tts-button').addEventListener('click', textToSpeech);

        // Handle Enter key press in the input field
        document.querySelector('.prompt-input').addEventListener('keypress', function(event) {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault(); // Prevent default to avoid newline in textarea
                submitPrompt();
            }
        });
    </script>
</body>
</html>
