<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="description" content="A comprehensive guide for Ruby gem installation and Google Generative AI integration. Learn about package structure, dependencies, and how to implement AI search functionality with clean code examples.">
    <meta name="copyright" content="Â© 2025 Niladri Das. All rights reserved.">
    <meta name="author" content="Niladri Das">
    <meta name="publish_date" content="2025-04-22">
    <meta name="date" content="2025-04-22">

    <!-- Open Graph / Social Media Meta Tags -->
    <meta property="og:title" content="Gem Installation & Google Generative AI">
    <meta property="og:description" content="A clean, minimal interface for Ruby gem installation and Google's Generative AI. Explore algorithm solutions, API integration examples, and learn how to implement AI search functionality with the latest Gemini models.">
    <meta property="og:image" content="https://raw.githubusercontent.com/bniladridas/gemini-ai-search/main/static/img/png/og-image.png">
    <meta property="og:url" content="{{ request.url_root }}">
    <meta property="og:type" content="website">
    <meta property="og:author" content="Niladri Das">
    <meta property="article:published_time" content="2025-04-22">
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@bniladridas">

    <title>Gem Installation & Google Generative AI</title>
    <link rel="icon" href="{{ url_for('static', filename='img/favicon.svg') }}" type="image/svg+xml">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/marked/marked.min.css">
    <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        :root {
            --text: #2c2c2c;
            --muted: #6b6b6b;
            --background: #fff;
            --spacing: clamp(1.5rem, 5vw, 2.5rem);
            --google-blue: #4285F4;
            --google-red: #EA4335;
            --google-text: #202124;
            --subtle-bg: rgba(0,0,0,0.02);
            --subtle-border: rgba(0,0,0,0.06);
            --subtle-shadow: rgba(0,0,0,0.05);
        }

        * {
            box-sizing: border-box;
            margin: 0;
        }

        html {
            -webkit-text-size-adjust: 100%;
        }

        body {
            font-family: -apple-system, system-ui, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            font-size: 15px;
            line-height: 1.6;
            max-width: 40rem;
            width: 100%;
            margin: var(--spacing) auto;
            padding: 0 var(--spacing);
            color: var(--text);
            background: var(--background);
            text-rendering: optimizeLegibility;
            -webkit-font-smoothing: antialiased;
            -moz-osx-font-smoothing: grayscale;
            box-sizing: border-box;
            letter-spacing: -0.01em;
        }

        h1 {
            font-size: 1.15rem;
            font-weight: 600;
            letter-spacing: -0.015em;
            margin-bottom: calc(var(--spacing) * 1.2);
            color: var(--text);
        }

        h2 {
            font-size: 0.9rem;
            font-weight: 500;
            margin-top: calc(var(--spacing) * 0.8);
            color: var(--google-red);
            letter-spacing: -0.01em;
            margin-bottom: 0.3rem;
        }

        p {
            font-size: 0.85rem;
            color: var(--muted);
            line-height: 1.5;
            margin-bottom: 0.3rem;
        }

        code {
            font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;
            font-size: 0.82rem;
            line-height: 1.5;
            display: block;
            margin: 0.4rem 0 calc(var(--spacing) * 0.9);
            color: var(--text);
            background: var(--subtle-bg);
            padding: 0.8rem 1rem;
            border-radius: 6px;
            overflow-x: auto;
        }

        body > p:last-child {
            margin-top: var(--spacing);
            font-size: 0.8rem;
            color: var(--muted);
            opacity: 0.8;
        }

        h1 {
            margin-top: calc(var(--spacing) * 2);
            padding-top: calc(var(--spacing) * 1);
            border-top: 1px solid var(--subtle-border);
        }

        h1:first-of-type {
            margin-top: 0;
            padding-top: 0;
            border-top: none;
        }

        .simple-search {
            margin-top: 0.8rem;
            margin-bottom: 2rem;
        }

        .prompt-input {
            width: 100%;
            padding: 0.8rem 1rem;
            font-family: inherit;
            font-size: 0.85rem;
            border: 1px solid var(--subtle-border);
            border-radius: 8px;
            background: var(--subtle-bg);
            margin-bottom: 0.8rem;
            transition: all 0.2s ease;
            resize: vertical;
        }

        .prompt-input:focus {
            outline: none;
            border-color: var(--google-red);
            background: white;
            box-shadow: 0 2px 8px var(--subtle-shadow);
        }

        .prompt-button {
            padding: 0.6rem 1.2rem;
            font-family: inherit;
            font-size: 0.85rem;
            font-weight: 500;
            background: var(--google-red);
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            opacity: 0.95;
            display: block;
            margin-bottom: 1.2rem;
            transition: all 0.2s ease;
        }

        .prompt-button:hover {
            opacity: 1;
            transform: translateY(-1px);
            box-shadow: 0 2px 5px var(--subtle-shadow);
        }

        .response-container {
            padding: 1.2rem;
            background: var(--subtle-bg);
            border-radius: 8px;
            font-size: 0.85rem;
            line-height: 1.6;
            min-height: 3rem;
            font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, monospace;
            border: 1px solid var(--subtle-border);
            margin-bottom: 1rem;
        }

        .tts-button {
            padding: 0.6rem 1.2rem;
            font-family: inherit;
            font-size: 0.85rem;
            font-weight: 500;
            background: var(--google-red);
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            opacity: 0.95;
            display: none;
            margin-top: 0.8rem;
            transition: all 0.2s ease;
        }

        .tts-button:hover {
            opacity: 1;
            transform: translateY(-1px);
            box-shadow: 0 2px 5px var(--subtle-shadow);
        }

        .audio-player {
            width: 100%;
            margin-top: 0.8rem;
            display: none;
            border-radius: 8px;
            overflow: hidden;
        }

        /* Image generation styles */
        .image-generation {
            margin-top: 0.8rem;
            margin-bottom: 2rem;
        }

        .image-prompt-input {
            width: 100%;
            padding: 0.8rem 1rem;
            font-family: inherit;
            font-size: 0.85rem;
            border: 1px solid var(--subtle-border);
            border-radius: 8px;
            background: var(--subtle-bg);
            margin-bottom: 0.8rem;
            transition: all 0.2s ease;
            resize: vertical;
        }

        .image-prompt-input:focus {
            outline: none;
            border-color: var(--google-red);
            background: white;
            box-shadow: 0 2px 8px var(--subtle-shadow);
        }

        .image-prompt-button {
            padding: 0.6rem 1.2rem;
            font-family: inherit;
            font-size: 0.85rem;
            font-weight: 500;
            background: var(--google-red);
            color: white;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            opacity: 0.95;
            display: block;
            margin-bottom: 1.2rem;
            transition: all 0.2s ease;
        }

        .image-prompt-button:hover {
            opacity: 1;
            transform: translateY(-1px);
            box-shadow: 0 2px 5px var(--subtle-shadow);
        }

        .image-container {
            min-height: 3rem;
            border-radius: 8px;
            overflow: hidden;
        }

        #generated-image {
            border-radius: 8px;
            box-shadow: 0 2px 10px var(--subtle-shadow);
        }

        /* Profile avatar styles */
        .profile-container {
            display: flex;
            justify-content: center;
            margin: 1.2rem 0 1.5rem;
        }

        .profile-avatar {
            width: 110px;
            height: 110px;
            border-radius: 50%;
            object-fit: cover;
            border: 2px solid var(--google-red);
            box-shadow: 0 4px 12px var(--subtle-shadow);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .profile-avatar:hover {
            transform: scale(1.03);
            box-shadow: 0 6px 16px var(--subtle-shadow);
        }

        /* Style for links - changing from default blue to grey */
        a {
            color: var(--muted);
            text-decoration: none;
            border-bottom: 1px solid var(--subtle-border);
            transition: all 0.2s ease;
            padding-bottom: 1px;
        }

        a:hover {
            color: var(--google-red);
            border-bottom-color: var(--google-red);
        }

        /* Mobile-specific styles */
        @media (max-width: 600px) {
            :root {
                --spacing: 1rem;
            }

            body {
                font-size: 14px;
                padding: 0 1rem;
                max-width: 100%;
            }

            code {
                font-size: 0.75rem;
                line-height: 1.4;
                padding: 0.7rem;
                border-radius: 6px;
            }

            .prompt-input, .image-prompt-input {
                font-size: 0.8rem;
                padding: 0.7rem;
            }

            .prompt-button, .image-prompt-button, .tts-button {
                font-size: 0.8rem;
                padding: 0.5rem 1rem;
            }

            h1 {
                font-size: 1.05rem;
                margin-bottom: 1.5rem;
            }

            h2 {
                font-size: 0.85rem;
            }

            p {
                font-size: 0.8rem;
            }

            .profile-avatar {
                width: 90px;
                height: 90px;
            }

            .response-container {
                padding: 1rem;
                font-size: 0.8rem;
            }
        }

        /* Release button styles */
        .release-container {
            margin: 1rem 0;
        }

        .release-button {
            display: flex;
            align-items: center;
            padding: 1rem;
            background: var(--subtle-bg);
            border: 1px solid var(--subtle-border);
            border-radius: 8px;
            text-decoration: none;
            color: var(--text);
            transition: all 0.2s ease;
            gap: 1rem;
        }

        .release-button:hover {
            transform: translateY(-1px);
            box-shadow: 0 2px 5px var(--subtle-shadow);
            background: white;
        }

        .release-icon {
            color: var(--google-blue);
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .release-info {
            flex: 1;
            display: flex;
            flex-direction: column;
        }

        .release-tag {
            font-weight: 600;
            color: var(--google-blue);
            font-size: 0.9rem;
        }

        .release-date {
            color: var(--muted);
            font-size: 0.8rem;
            margin-top: 0.2rem;
        }

        .release-arrow {
            color: var(--google-red);
            font-size: 1.2rem;
            font-weight: 500;
        }

        /* Cookie notification styles */
        .cookie-notification {
            position: fixed;
            bottom: 0;
            left: 0;
            right: 0;
            background-color: rgba(0, 0, 0, 0.85);
            color: white;
            padding: 1rem;
            display: flex;
            justify-content: space-between;
            align-items: center;
            z-index: 1000;
            font-size: 0.85rem;
            box-shadow: 0 -2px 10px rgba(0, 0, 0, 0.2);
            transform: translateY(100%);
            transition: transform 0.3s ease-in-out;
        }

        .cookie-notification.show {
            transform: translateY(0);
        }

        .cookie-text {
            flex: 1;
            padding-right: 1rem;
            line-height: 1.4;
        }

        .cookie-text a {
            color: var(--google-red);
            border-bottom: 1px solid var(--google-red);
        }

        .cookie-text a:hover {
            color: white;
            border-bottom-color: white;
        }

        .cookie-button {
            background-color: var(--google-red);
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            cursor: pointer;
            font-weight: 500;
            white-space: nowrap;
            transition: background-color 0.2s ease;
        }

        .cookie-button:hover {
            background-color: #d32f2f;
        }

        @media (max-width: 600px) {
            .cookie-notification {
                flex-direction: column;
                padding: 0.8rem;
            }

            .cookie-text {
                padding-right: 0;
                padding-bottom: 0.8rem;
                font-size: 0.8rem;
            }
        }
    </style>
</head>
<body>
    <div class="logo-container">
        <img src="{{ url_for('static', filename='img/logo.svg') }}" alt="ND Logo" class="logo">
    </div>
    <div class="nav-links" style="text-align: center; margin-bottom: 1.5rem;">
        <a href="#privacy-legal" style="font-size: 0.8rem; margin: 0 0.5rem;">Privacy & Legal</a>
    </div>
    <h1>Gem Installation</h1>

    <h2>Start</h2>
    <p>Initial command</p>
    <code>sudo gem install friday_gemini_ai</code>

    <h2>Challenge</h2>
    <p>Version mismatch</p>
    <code>ruby -v</code>

    <h2>Solution</h2>
    <p>Version update</p>
    <code>rbenv global 3.2.2</code>

    <h2>Result</h2>
    <p>Success</p>
    <code>Successfully installed httparty-0.21.0
4 gems installed</code>

    <p>Always verify Ruby version before installing gems.</p>

    <h1>Google Generative AI</h1>

    <h2>Package Info</h2>
    <p>Details (<a href="https://ai.google.dev/" target="_blank" rel="noopener noreferrer">Google AI Studio</a>)</p>
    <code>Name: google-generativeai
Version: 0.3.1
Summary: Google Generative AI High level API client library and tools.
Home-page: https://github.com/google/generative-ai-python
Author: Google LLC
Author-email: googleapis-packages@google.com
License: Apache 2.0
Location: /Users/niladridas/Desktop/te/.venv/lib/python3.13/site-packages
Requires: google-ai-generativelanguage, google-api-core, google-auth, protobuf, tqdm
Required-by:</code>

    <h2>Latest Release</h2>
    <p>Version 1.0.2 is now available</p>
    <div class="release-container">
        <a href="https://github.com/bniladridas/gemini-ai-search/releases/tag/v1.0.2"
           target="_blank"
           rel="noopener noreferrer"
           class="release-button">
            <div class="release-icon">
                <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
                    <path d="M12 2L2 7L12 12L22 7L12 2Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                    <path d="M2 17L12 22L22 17" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                    <path d="M2 12L12 17L22 12" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
                </svg>
            </div>
            <div class="release-info">
                <span class="release-tag">v1.0.2</span>
                <span class="release-date">May 14, 2025</span>
            </div>
            <div class="release-arrow">â</div>
        </a>
    </div>
    <p style="font-size: 0.8rem; margin-top: 0.5rem;">See the <a href="https://github.com/bniladridas/gemini-ai-search/blob/main/CHANGELOG.md" target="_blank" rel="noopener noreferrer">changelog</a> for details on this release.</p>

    <h2>Package Structure</h2>
    <p>Key components</p>
    <code>google/generativeai - Main package directory
google_generativeai-0.3.1-py3.11-nspkg.pth
google_generativeai-0.3.1.dist-info/ - Package metadata</code>

    <h2>Dependencies</h2>
    <p>Installed packages</p>
    <code>google_ai_generativelanguage-0.4.0.dist-info
google_api_core-2.24.2.dist-info
google_auth-2.39.0.dist-info
googleapis_common_protos-1.70.0.dist-info</code>

    <h1>Algorithm Problems</h1>

    <h2>Business & Economic Impact</h2>
    <p>How algorithmic solutions drive business value</p>
    <code># BUSINESS VALUE OF ALGORITHMIC SOLUTIONS
# 1. Operational Efficiency
#    - Reduced computational costs through optimized algorithms
#    - Faster processing enables real-time decision making
#    - Improved resource allocation and utilization

# 2. Customer Experience
#    - Faster response times improve user satisfaction
#    - More accurate results build trust and reliability
#    - Personalized experiences through pattern recognition

# 3. Cost Reduction
#    - Fewer API calls through optimized requests
#    - Lower infrastructure requirements
#    - Reduced support and maintenance costs

# 4. Competitive Advantage
#    - Faster time-to-market for new features
#    - More reliable service with fewer outages
#    - Better scalability to handle growth

# 5. Innovation Enablement
#    - Complex features become possible through efficient algorithms
#    - AI capabilities can be fully leveraged
#    - New business models emerge from technical capabilities

# CASE STUDY: Image Generation Fix
# By solving the "No current event loop in thread" error:
# - Restored a key product feature that was completely non-functional
# - Eliminated wasted API costs on failed requests
# - Improved user trust by delivering on promised capabilities
# - Reduced support burden from user complaints
# - Enabled scaling to handle multiple concurrent requests</code>

    <h2>Error: Network response was not ok</h2>
    <p>Problem: The Gemini API integration was failing with "Network response was not ok" error due to incorrect API usage.</p>
    <code># INCORRECT APPROACH (causing the error)
# This code was trying to use a Client class that doesn't exist in the installed version

client = genai.Client(
    api_key=os.environ.get("GEMINI_API_KEY"),
)

response = client.models.generate_content(
    model=model,
    contents=contents,
    config=generate_content_config,
)

# CORRECT APPROACH (solution)
# Configure the API globally and use GenerativeModel directly

# Set up the API key globally
genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))

# Create a GenerativeModel instance
model = genai.GenerativeModel('gemini-1.5-flash')

# Generate the response with a simpler interface
response = model.generate_content(prompt)</code>

    <h2>Error: Thinking is not enabled</h2>
    <p>Problem: The image generation API was failing with "Thinking is not enabled for models/gemini-2.0-flash-exp-image-generation" error.</p>
    <code># INCORRECT APPROACH (causing the error)
# This code was trying to use thinking_config which is not supported by the image generation model

generate_content_config = types.GenerateContentConfig(
    thinking_config = types.ThinkingConfig(
        thinking_budget=0,
    ),
    response_modalities=[
        "image",
        "text",
    ],
    response_mime_type="text/plain",
)

# CORRECT APPROACH (solution)
# Remove the thinking_config parameter

generate_content_config = types.GenerateContentConfig(
    response_modalities=[
        "image",
        "text",
    ],
    response_mime_type="text/plain",
)</code>

    <h2>Error: No current event loop in thread</h2>
    <p>Problem: The image generation feature was failing with "There is no current event loop in thread" error and returning text instead of images, causing business impact through poor user experience and wasted API resources.</p>
    <code># BUSINESS IMPACT
# 1. User frustration and potential service abandonment
# 2. Wasted API calls and associated costs
# 3. Increased support burden for troubleshooting
# 4. Reduced trust in AI capabilities

# INCORRECT APPROACH (causing the error)
# This code was trying to use asyncio functionality in a threaded environment without proper setup

@app.route('/api/generate-image', methods=['POST'])
def generate_image():
    try:
        # Initialize the Google Genai client
        client = google_genai.Client(
            api_key=os.environ.get("GEMINI_API_KEY"),
        )

        # Generate the image - THIS FAILS with "No current event loop in thread"
        response = client.models.generate_content(
            model=model,
            contents=contents,
            config=generate_content_config,
        )

        # Process response...
    except Exception as e:
        print("Exception in generate_image:", e)
        return jsonify({'error': str(e)}), 500

# CORRECT APPROACH (solution)
# Properly handle asyncio event loop in threaded environment

@app.route('/api/generate-image', methods=['POST'])
def generate_image():
    try:
        # Import asyncio for event loop handling
        import asyncio

        # Function to run in the event loop
        async def generate_image_async():
            # Initialize client and generate image...
            return response

        # Create a new event loop and run the async function
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        response = loop.run_until_complete(generate_image_async())
        loop.close()

        # Also improved prompt formatting:
        # From: text=prompt
        # To: text=f"Generate an image of: {prompt}"

        # Process response...
    except Exception as e:
        print("Exception in generate_image:", e)
        return jsonify({'error': str(e)}), 500</code>

    <h2>Two Sum</h2>
    <p>Problem: Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.</p>
    <code># Time Complexity: O(n)
# Space Complexity: O(n)

def twoSum(nums, target):
    # Create a hash map to store values and their indices
    hash_map = {}

    # Iterate through the array
    for i, num in enumerate(nums):
        # Calculate the complement
        complement = target - num

        # If complement exists in hash map, return its index and current index
        if complement in hash_map:
            return [hash_map[complement], i]

        # Otherwise, add current number and its index to hash map
        hash_map[num] = i

    # If no solution is found
    return []</code>

    <h2>Maximum Subarray</h2>
    <p>Problem: Given an integer array nums, find the contiguous subarray with the largest sum and return its sum.</p>
    <code># Time Complexity: O(n)
# Space Complexity: O(1)

def maxSubArray(nums):
    # Initialize variables
    current_sum = max_sum = nums[0]

    # Iterate through the array starting from the second element
    for num in nums[1:]:
        # Either start a new subarray or continue the previous one
        current_sum = max(num, current_sum + num)

        # Update max_sum if current_sum is greater
        max_sum = max(max_sum, current_sum)

    return max_sum</code>

    <h2>Merge Sort</h2>
    <p>Problem: Implement the merge sort algorithm to sort an array of integers in ascending order.</p>
    <code># Time Complexity: O(n log n)
# Space Complexity: O(n)

def merge_sort(arr):
    # Base case: if array has 0 or 1 element, it's already sorted
    if len(arr) <= 1:
        return arr

    # Divide the array into two halves
    mid = len(arr) // 2
    left = arr[:mid]
    right = arr[mid:]

    # Recursively sort both halves
    left = merge_sort(left)
    right = merge_sort(right)

    # Merge the sorted halves
    return merge(left, right)

def merge(left, right):
    result = []
    i = j = 0

    # Compare elements from both arrays and add the smaller one to result
    while i < len(left) and j < len(right):
        if left[i] <= right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1

    # Add any remaining elements
    result.extend(left[i:])
    result.extend(right[j:])

    return result</code>

    <h2>Binary Search</h2>
    <p>Problem: Implement binary search to find a target value in a sorted array.</p>
    <code># Time Complexity: O(log n)
# Space Complexity: O(1)

def binary_search(nums, target):
    left, right = 0, len(nums) - 1

    while left <= right:
        # Calculate middle index
        mid = left + (right - left) // 2

        # Check if target is at the middle
        if nums[mid] == target:
            return mid

        # If target is greater, ignore left half
        elif nums[mid] < target:
            left = mid + 1

        # If target is smaller, ignore right half
        else:
            right = mid - 1

    # Target not found
    return -1</code>

    <h2>Longest Palindromic Substring</h2>
    <p>Problem: Given a string s, return the longest palindromic substring in s.</p>
    <code># Time Complexity: O(nÂ²)
# Space Complexity: O(1)

def longest_palindrome(s):
    if not s:
        return ""

    start = 0  # Start index of the longest palindrome
    max_len = 1  # Length of the longest palindrome

    # Helper function to expand around center
    def expand_around_center(left, right):
        while left >= 0 and right < len(s) and s[left] == s[right]:
            left -= 1
            right += 1
        return right - left - 1  # Length of palindrome

    # Check each position as a potential center
    for i in range(len(s)):
        # Odd length palindrome (single character center)
        len1 = expand_around_center(i, i)

        # Even length palindrome (between two characters)
        len2 = expand_around_center(i, i + 1)

        # Get the maximum length from both cases
        length = max(len1, len2)

        # Update if we found a longer palindrome
        if length > max_len:
            max_len = length
            start = i - (length - 1) // 2

    return s[start:start + max_len]</code>

    <h1>Niladri Das</h1>
    <div class="profile-container">
        <img src="https://avatars.githubusercontent.com/u/125604915?v=4" alt="Niladri Das" class="profile-avatar">
    </div>
    <h2>Software Engineer</h2>
    <p>Skills</p>
    <code>C++, Python, JavaScript, Flask, React, Machine Learning, API Integration</code>

    <h2>Experience</h2>
    <p>Background</p>
    <code>Specialized in building AI-powered applications and integrating with generative AI models</code>

    <h2>Projects</h2>
    <p>Recent work</p>
    <code>Gemini API Integration, Algorithm Problem Solver, Responsive Web Applications</code>

    <h2>Contact</h2>
    <p>Professional</p>
    <code>LinkedIn: <a href="https://www.linkedin.com/in/bniladridas/" target="_blank" rel="noopener noreferrer">Niladri Das</a></code>

    <h1>AI Search</h1>
    <h2>Ask a Question</h2>
    <p>Enter your prompt and optionally listen to the response. Learn about <a href="https://ai.google.dev/gemini-api/docs/prompting-intro#examples" target="_blank" rel="noopener noreferrer">effective prompting techniques</a>.</p>
    <div class="simple-search">
        <textarea class="prompt-input" placeholder="Enter your question or prompt here..." rows="3"></textarea>
        <button class="prompt-button">Submit</button>
        <div class="response-container" id="response"></div>
        <button class="tts-button" id="tts-button">Listen (Text to Speech)</button>
        <audio class="audio-player" id="audio-player" controls></audio>
    </div>

    <h2>Implementation</h2>
    <p>Python code for text generation</p>
    <code># To run this code you need to install the following dependencies:
# pip install google-generativeai

import os
import google.generativeai as genai

# Configure the API
genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))

# Create a model instance with the newer model
model = genai.GenerativeModel('gemini-2.5-flash-preview-04-17')

# Generate content
response = model.generate_content("Your prompt here")

# Print the response
print(response.text)</code>

    <h2>Text-to-Speech Synthesis</h2>
    <p>Convert AI responses to natural-sounding speech</p>
    <code># Text-to-Speech implementation using Google's gTTS library
# pip install gtts

from gtts import gTTS
import os
import uuid
import tempfile

# Create a directory for temporary audio files
TEMP_AUDIO_DIR = os.path.join(tempfile.gettempdir(), 'gemini_tts')
os.makedirs(TEMP_AUDIO_DIR, exist_ok=True)

# Convert text to speech
def text_to_speech(text):
    # Generate a unique filename
    filename = f"{uuid.uuid4()}.mp3"
    filepath = os.path.join(TEMP_AUDIO_DIR, filename)

    # Convert text to speech using Google's TTS engine
    tts = gTTS(text=text, lang='en', slow=False)
    tts.save(filepath)

    # Return the file path to be served to the client
    return filepath</code>

    <h1>AI Image Generation</h1>
    <h2>Create Images with AI</h2>
    <p>Enter a description to generate an image. Try detailed prompts for better results. Check out <a href="https://github.com/bniladridas/gemini-ai-search" target="_blank" rel="noopener noreferrer">our GitHub repository</a> for more examples from the Google AI team.</p>
    <div class="image-generation">
        <textarea class="image-prompt-input" placeholder="Describe the image you want to generate..." rows="3"></textarea>
        <button class="image-prompt-button">Generate Image</button>
        <div class="image-container">
            <img id="generated-image" style="display: none; max-width: 100%; margin-top: 1rem;">
            <div id="image-message" style="display: none;"></div>
        </div>
    </div>

    <h2>Implementation</h2>
    <p>Python code for image generation</p>
    <code># Image Generation implementation using Google's Gemini API
# pip install google-genai

import os
import uuid
import tempfile
import mimetypes
from google import genai
from google.genai import types

# Create a directory for temporary image files
TEMP_IMAGE_DIR = os.path.join(tempfile.gettempdir(), 'gemini_images')
os.makedirs(TEMP_IMAGE_DIR, exist_ok=True)

# Initialize the client
client = genai.Client(
    api_key=os.environ.get("GEMINI_API_KEY"),
)

# Generate an image from text
def generate_image(prompt):
    # Set up the model and content
    model = "gemini-2.0-flash-exp-image-generation"
    contents = [
        types.Content(
            role="user",
            parts=[
                types.Part.from_text(text=prompt),
            ],
        ),
    ]

    # Configure the generation parameters
    config = types.GenerateContentConfig(
        response_modalities=["image", "text"],
    )

    # Generate the image
    response = client.models.generate_content(
        model=model,
        contents=contents,
        config=config,
    )

    # Return the generated image
    return response</code>

    <h1 id="privacy-legal">Privacy & Legal</h1>
    <h2>Privacy Policy</h2>
    <p>Last updated: April 23, 2025</p>
    <code>This Privacy Policy describes how we collect, use, and handle your information when you use our services. By using this website, you agree to the collection and use of information in accordance with this policy.

Information Collection and Use:
- We collect information you provide directly to us, such as prompts entered into the search or image generation features.
- We use this information to provide, maintain, and improve our services.
- Your prompts may be temporarily stored to process your requests but are not permanently stored or used for training purposes.

Data Storage and Caching:
- Generated images and audio files are stored temporarily in a server-side temporary directory and are not permanently retained. This is implemented in our code:
  * For audio: `TEMP_AUDIO_DIR = os.path.join(tempfile.gettempdir(), 'gemini_tts')`
  * For images: `TEMP_IMAGE_DIR = os.path.join(tempfile.gettempdir(), 'gemini_images')`
- Your browser may cache content, including generated images and audio files, to improve performance.
- We use browser-based URL blob objects to display generated images and play audio files.
- The application uses the Fetch API for network requests, which may implement caching: `fetch('/api/generate-image', {...})` and `fetch('/api/text-to-speech', {...})`
- We do not sell or share your data with third parties except as necessary to provide our services.

Third-Party Services and Technologies:
- This website uses Google's Generative AI services. Your interactions may be subject to Google's privacy policies.
- We use Flask, a Python web framework that may set session cookies for security purposes.
- We use Flask-CORS (Cross-Origin Resource Sharing) to enable secure API requests from the browser, as shown in our code: `app = Flask(__name__); CORS(app)  # Enable CORS for all routes`
- We use the gTTS (Google Text-to-Speech) service to convert text to speech: `tts = gTTS(text=text, lang='en', slow=False)`
- We use the Google Generative AI API for text and image generation: `model = genai.GenerativeModel('gemini-2.5-flash-preview-04-17')`
- For more information about Google's privacy practices, visit: https://ai.google.dev/privacy

Cookies and Local Storage:
- This website may use browser storage mechanisms and cookies for technical purposes.
- The Flask framework we use may set session cookies for security purposes.
- When you use our text-to-speech or image generation features, your browser may cache these files locally.
- We use URL blob objects to display generated images and play audio files, which are temporarily stored in your browser's memory. This is evident in our code:
  * For audio: `const audioUrl = URL.createObjectURL(blob); audioPlayer.src = audioUrl;`
  * For images: `const imageUrl = URL.createObjectURL(blob); generatedImage.src = imageUrl;`
- Our JavaScript code uses the Fetch API which may utilize browser caching mechanisms.
- We do not use cookies for tracking or advertising purposes.

Changes to This Privacy Policy:
- We may update our Privacy Policy from time to time. We will notify you of any changes by posting the new Privacy Policy on this page.

Contact Us:
- If you have any questions about this Privacy Policy, please contact us.</code>

    <h2>Terms of Service</h2>
    <p>Effective date: April 23, 2025</p>
    <code>By accessing or using this website, you agree to be bound by these Terms of Service. If you disagree with any part of the terms, you may not access the service.

Use of Service:
- This service is provided for informational and educational purposes only.
- You may not use this service for any illegal or unauthorized purpose.
- You agree not to modify, adapt, or hack the service or modify another website to falsely imply that it is associated with this service.

Content and Conduct:
- You are responsible for all content you submit through our service.
- You agree not to use the service to generate or distribute content that is illegal, harmful, threatening, abusive, harassing, defamatory, or otherwise objectionable.
- We reserve the right to remove any content that violates these terms or is otherwise objectionable.

Intellectual Property:
- The service and its original content, features, and functionality are owned by Niladri Das and are protected by international copyright, trademark, patent, trade secret, and other intellectual property laws.

Limitation of Liability:
- In no event shall we be liable for any indirect, incidental, special, consequential or punitive damages, including without limitation, loss of profits, data, use, goodwill, or other intangible losses.

Governing Law:
- These Terms shall be governed by the laws of the jurisdiction in which the service provider is established, without regard to its conflict of law provisions.

Changes to Terms:
- We reserve the right to modify or replace these Terms at any time. It is your responsibility to review these Terms periodically for changes.</code>

    <h2>Copyright Notice</h2>
    <p>Legal information</p>
    <code>Â© 2025 Niladri Das. All rights reserved. Using this template or any part of this design is strictly prohibited without direct permission from the author.</code>

    <script>
        // Initialize marked.js for markdown rendering
        marked.setOptions({
            breaks: true,
            gfm: true
        });

        // Function to handle prompt submission
        function submitPrompt() {
            const promptInput = document.querySelector('.prompt-input').value;
            const responseContainer = document.getElementById('response');
            const ttsButton = document.getElementById('tts-button');
            const audioPlayer = document.getElementById('audio-player');

            // Hide TTS button and audio player when submitting a new prompt
            ttsButton.style.display = 'none';
            audioPlayer.style.display = 'none';
            audioPlayer.pause();
            audioPlayer.src = '';

            if (!promptInput.trim()) {
                responseContainer.innerHTML = '<em>Please enter a prompt</em>';
                return;
            }

            // Show loading state
            responseContainer.innerHTML = '<em>Thinking...</em>';

            // Make an actual API call to the Flask backend
            fetch('/api/generate', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ prompt: promptInput })
            })
            .then(response => {
                if (!response.ok) {
                    throw new Error('Network response was not ok');
                }
                return response.json();
            })
            .then(data => {
                // Render the response as markdown
                responseContainer.innerHTML = marked.parse(data.response);

                // Show the TTS button if we have a response
                if (data.response && data.response.trim()) {
                    ttsButton.style.display = 'block';
                    // Store the response text as a data attribute on the button
                    ttsButton.setAttribute('data-text', data.response);
                }
            })
            .catch(error => {
                console.error('Error:', error);
                responseContainer.innerHTML = `<em>Error: ${error.message}</em>`;
            });
        }

        // Function to handle text-to-speech
        function textToSpeech() {
            const ttsButton = document.getElementById('tts-button');
            const audioPlayer = document.getElementById('audio-player');
            const text = ttsButton.getAttribute('data-text');

            if (!text) {
                return;
            }

            // Disable the button while processing
            ttsButton.disabled = true;
            ttsButton.textContent = 'Processing...';

            // Make an API call to the text-to-speech endpoint
            fetch('/api/text-to-speech', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ text: text })
            })
            .then(response => {
                if (!response.ok) {
                    throw new Error('Network response was not ok');
                }
                return response.blob();
            })
            .then(blob => {
                // Create a URL for the audio blob
                const audioUrl = URL.createObjectURL(blob);

                // Set the audio source and display the player
                audioPlayer.src = audioUrl;
                audioPlayer.style.display = 'block';

                // Play the audio
                audioPlayer.play();

                // Re-enable the button
                ttsButton.disabled = false;
                ttsButton.textContent = 'Listen (Text to Speech)';
            })
            .catch(error => {
                console.error('Error:', error);
                alert(`Error generating speech: ${error.message}`);

                // Re-enable the button
                ttsButton.disabled = false;
                ttsButton.textContent = 'Listen (Text to Speech)';
            });
        }

        // Function to handle image generation
        function generateImage() {
            const promptInput = document.querySelector('.image-prompt-input').value;
            const generatedImage = document.getElementById('generated-image');
            const imageMessage = document.getElementById('image-message');
            const imageButton = document.querySelector('.image-prompt-button');

            // Hide previous image and message
            generatedImage.style.display = 'none';
            imageMessage.style.display = 'none';

            if (!promptInput.trim()) {
                imageMessage.textContent = 'Please enter a prompt';
                imageMessage.style.display = 'block';
                return;
            }

            // Disable the button and show loading state
            imageButton.disabled = true;
            imageButton.textContent = 'Generating...';
            imageMessage.textContent = 'Generating your image. This may take a minute...';
            imageMessage.style.display = 'block';

            // Make an API call to the image generation endpoint
            fetch('/api/generate-image', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ prompt: promptInput })
            })
            .then(response => {
                if (!response.ok) {
                    return response.json().then(data => {
                        throw new Error(data.error || 'Failed to generate image');
                    });
                }

                // Check if the response is JSON (error message) or blob (image)
                const contentType = response.headers.get('content-type');
                if (contentType && contentType.includes('application/json')) {
                    return response.json().then(data => {
                        throw new Error(data.message || data.error || 'Failed to generate image');
                    });
                }

                return response.blob();
            })
            .then(blob => {
                // Create a URL for the image blob
                const imageUrl = URL.createObjectURL(blob);

                // Set the image source and display it
                generatedImage.src = imageUrl;
                generatedImage.style.display = 'block';
                imageMessage.style.display = 'none';

                // Re-enable the button
                imageButton.disabled = false;
                imageButton.textContent = 'Generate Image';
            })
            .catch(error => {
                console.error('Error:', error);
                imageMessage.textContent = `Error: ${error.message}`;
                imageMessage.style.display = 'block';

                // Re-enable the button
                imageButton.disabled = false;
                imageButton.textContent = 'Generate Image';
            });
        }

        // Handle button clicks
        document.querySelector('.prompt-button').addEventListener('click', submitPrompt);
        document.getElementById('tts-button').addEventListener('click', textToSpeech);
        document.querySelector('.image-prompt-button').addEventListener('click', generateImage);

        // Handle Enter key press in the input fields
        document.querySelector('.prompt-input').addEventListener('keypress', function(event) {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault(); // Prevent default to avoid newline in textarea
                submitPrompt();
            }
        });

        document.querySelector('.image-prompt-input').addEventListener('keypress', function(event) {
            if (event.key === 'Enter' && !event.shiftKey) {
                event.preventDefault(); // Prevent default to avoid newline in textarea
                generateImage();
            }
        });
    </script>

    <!-- Cookie Notification Banner -->
    <div class="cookie-notification" id="cookie-notification">
        <div class="cookie-text">
            This website uses cookies and local storage to enhance your experience. By continuing to use this site, you agree to our use of cookies and data storage as described in our <a href="#privacy-legal">Privacy Policy</a>.
        </div>
        <button class="cookie-button" id="accept-cookies">Accept</button>
    </div>

    <script>
        // Cookie notification functionality
        document.addEventListener('DOMContentLoaded', function() {
            const cookieNotification = document.getElementById('cookie-notification');
            const acceptCookiesButton = document.getElementById('accept-cookies');

            // Check if user has already accepted cookies
            const cookiesAccepted = localStorage.getItem('cookiesAccepted');

            if (!cookiesAccepted) {
                // Show the notification with a slight delay for better UX
                setTimeout(function() {
                    cookieNotification.classList.add('show');
                }, 1000);
            }

            // Handle accept button click
            acceptCookiesButton.addEventListener('click', function() {
                localStorage.setItem('cookiesAccepted', 'true');
                cookieNotification.classList.remove('show');
            });
        });
    </script>
</body>
</html>
